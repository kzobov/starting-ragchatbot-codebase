# RAG System Query Processing Flow

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ User
    participant Frontend as ğŸŒ Frontend (script.js)
    participant FastAPI as ğŸš€ FastAPI (app.py)
    participant RAG as ğŸ§  RAG System
    participant SessionMgr as ğŸ“ Session Manager
    participant AIGen as ğŸ¤– AI Generator
    participant Claude as â˜ï¸ Anthropic Claude
    participant ToolMgr as ğŸ”§ Tool Manager
    participant SearchTool as ğŸ” Search Tool
    participant VectorStore as ğŸ“Š Vector Store
    participant ChromaDB as ğŸ—ƒï¸ ChromaDB

    User->>Frontend: Types query & clicks send
    Frontend->>Frontend: Disable input, show loading
    Frontend->>Frontend: Add user message to chat
    
    Frontend->>+FastAPI: POST /api/query<br/>{query, session_id}
    FastAPI->>FastAPI: Validate request (Pydantic)
    FastAPI->>FastAPI: Create session_id if null
    
    FastAPI->>+RAG: query(user_query, session_id)
    RAG->>+SessionMgr: get_conversation_history(session_id)
    SessionMgr-->>-RAG: Previous messages context
    
    RAG->>RAG: Create prompt:<br/>"Answer question about course materials"
    RAG->>+AIGen: generate_response(prompt, history, tools, tool_manager)
    
    AIGen->>AIGen: Build system prompt + context
    AIGen->>+Claude: API call with tools available
    
    Note over Claude: Claude analyzes query<br/>Decides if search needed
    
    alt Claude uses search tool
        Claude-->>AIGen: tool_use response
        AIGen->>+ToolMgr: execute_tool(search_course_content, params)
        ToolMgr->>+SearchTool: execute(query, course_name, lesson_number)
        
        SearchTool->>+VectorStore: search(query, filters)
        VectorStore->>VectorStore: Generate query embedding
        VectorStore->>+ChromaDB: similarity_search()
        ChromaDB-->>-VectorStore: Matching documents + metadata
        VectorStore-->>-SearchTool: SearchResults object
        
        SearchTool->>SearchTool: Format results with context
        SearchTool->>SearchTool: Track sources for UI
        SearchTool-->>-ToolMgr: Formatted search results
        ToolMgr-->>-AIGen: Search results
        
        AIGen->>+Claude: Second API call with search results
        Claude-->>-AIGen: Final response based on search
    else Claude answers from general knowledge
        Claude-->>-AIGen: Direct response (no tools)
    end
    
    AIGen-->>-RAG: Generated response text
    RAG->>+ToolMgr: get_last_sources()
    ToolMgr-->>-RAG: Sources list
    RAG->>+SessionMgr: add_exchange(session_id, query, response)
    SessionMgr-->>-RAG: Updated history
    RAG-->>-FastAPI: (response_text, sources_list)
    
    FastAPI->>FastAPI: Create QueryResponse object
    FastAPI-->>-Frontend: JSON: {answer, sources, session_id}
    
    Frontend->>Frontend: Update session_id if new
    Frontend->>Frontend: Remove loading animation
    Frontend->>Frontend: Parse markdown & add response
    Frontend->>Frontend: Add collapsible sources
    Frontend->>User: Display response with sources
```

## Architecture Components

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[ğŸŒ Web Interface<br/>HTML/CSS/JS]
    end
    
    subgraph "API Layer"
        API[ğŸš€ FastAPI Server<br/>app.py]
    end
    
    subgraph "Orchestration Layer"
        RAG[ğŸ§  RAG System<br/>rag_system.py]
        Session[ğŸ“ Session Manager<br/>session_manager.py]
    end
    
    subgraph "AI Layer"
        AIGen[ğŸ¤– AI Generator<br/>ai_generator.py]
        Claude[â˜ï¸ Anthropic Claude API]
    end
    
    subgraph "Tool Layer"
        ToolMgr[ğŸ”§ Tool Manager<br/>search_tools.py]
        SearchTool[ğŸ” Course Search Tool<br/>search_tools.py]
    end
    
    subgraph "Storage Layer"
        VectorStore[ğŸ“Š Vector Store<br/>vector_store.py]
        ChromaDB[ğŸ—ƒï¸ ChromaDB<br/>Persistent Storage]
        Docs[ğŸ“š Course Documents<br/>docs/ folder]
    end
    
    subgraph "Processing Layer"
        DocProcessor[ğŸ“„ Document Processor<br/>document_processor.py]
    end
    
    UI --> API
    API --> RAG
    RAG --> Session
    RAG --> AIGen
    AIGen --> Claude
    AIGen --> ToolMgr
    ToolMgr --> SearchTool
    SearchTool --> VectorStore
    VectorStore --> ChromaDB
    DocProcessor --> VectorStore
    Docs --> DocProcessor
```

## Data Flow Summary

1. **User Input** â†’ Frontend captures query
2. **HTTP Request** â†’ POST to `/api/query` endpoint
3. **Session Context** â†’ Retrieve conversation history
4. **AI Processing** â†’ Claude with tool access
5. **Tool Execution** â†’ Search course content if needed
6. **Vector Search** â†’ Semantic similarity in ChromaDB
7. **Response Generation** â†’ AI synthesizes answer
8. **Source Tracking** â†’ Collect reference materials
9. **JSON Response** â†’ Structured response with sources
10. **UI Update** â†’ Display response with collapsible sources

## Key Design Features

- **Tool-Based Architecture**: AI decides when to search vs use general knowledge
- **Session Management**: Maintains conversation context across queries
- **Source Attribution**: Tracks and displays which courses/lessons were referenced
- **Semantic Search**: Vector embeddings for intelligent content matching
- **Error Handling**: Graceful fallbacks at each processing layer
- **Real-time UX**: Loading states and immediate response display